# Building Append-Only Data Structures

In the previous exercises we've build out a simple query system that can efficiently answer questions about our ever growing stats log. However, by adding something we call "embedded indexes" to our log we can actually make it much faster.

Embedded indexes are small amount of information we add to each log entry that acts as routing info to find entries before it as efficiently as possible. In the previous excercises each entry was completely independent, in that it didn't contain any information about prior entries. We were able to use a bisecting algorithm (binary search) only because the data is time-ordered.

Embedded indexes can be tricky to write as they surface a fundamental trade-off: they have to be small enough to not take up too much space in the log entry, but also be powerful enough to support finding what you are looking for efficiently. In some of the future exercises we'll look at data structures built with powerful embedded indexes that let us to quickly find generic string keys in the log, but that's getting a bit ahead of ourselves.

## Exercises

Let's update our stats collector so it uses an embedded index to make it faster to find entries.

With an embedded index, each block in the the log will be extended with an additional `index` field that looks like this (the data that made up the entire block in the previous exercise is now `stats` in the object below):

```js
{
  index: [
    { timestamp: Date, blockIndex: blockIndex - 1 },
    { timestamp: Date, blockIndex: blockIndex - 2 },
    { timestamp: Date, blockIndex: blockIndex - 4 },
    { timestamp: Date, blockIndex: blockIndex - 8 },
    ...
  ],
  stats: <the stats object>
}
```

Each entry in the index would contain the timestamp for a block and the corresponding block index for it.

Including the timestamps for the blocks at `index - 1`, `index - 2`, `index - 4`, ... `index - 2^n`, where `index - 2^n >= 0` makes finding the first block larger or equal to a specific timestamp easier and faster.

To do this we only need use the following algorithm:

```js
// Returns the index of the closest block using the index above.
// If the entry passed in is the closest it will return -1.
function closestBlock (timestamp, block) {
  // No index -> no closer block
  if (!block.index.length) return -1

  for (let i = 0; i < block.index.length; i++) {
    // If block is too old, the previous one must be closest
    if (block.index[i].timestamp < timestamp) {
      // First block (block.blockIndex - 1) is too old - block is closest
      if (i === 0) return -1
      // Otherwise the previous index block is closest
      return block.index[i - 1].blockIndex
    }
  }

  // Oldest one is closest
  return block.index[block.index.length - 1].blockIndex
}
```

To find the first entry larger than a specific timestamp we just need to use the `closestBlock` function from above.

1. First load the latest block.
2. Check if any block is closer using the `closestBlock` algorithm.
3. If so load that block and reuse the `closestsBlock` algorithm on and see 2.

To generate the index we on the writer can use the following algorithm:

```js
const JUMP_FACTOR = 2

const index = []
let distance = 1
let nextBlockIndex = core.length

while (nextBlockIndex - distance >= 0) {
  const blockIndex = nextBlockIndex - distance
  const block = await core.get(blockIndex)

  index.push({
    timestamp: block.stats.timestamp,
    blockIndex
  })

  distance *= JUMP_FACTOR
}
```

Notice how by increasing the JUMP_FACTOR, we can decrease the size of the embedded index in each block, because each block will point to fewer previous blocks (separated by larger distances).

#### Exercise 1

Update the stats collector writer to add the embedded index using the technique above.
To verify it, update your reader to use the embedded index to find specific blocks close to a timestamp.

#### Exercise 2

Play around with different JUMP_FACTOR values, and notice how there's a trade-off between the index overhead (the total sizes of all the blocks in the core) and the number of downloads that are required to answer your query. The larger the index, the fewer downloads are required.

## Stuck?

Take a look at the [solution here](/solutions/07/index.js).

[Once your embedded index log is working continue to Problem 8](08.md)
